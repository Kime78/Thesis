import subprocess
import json
import os

def add_to_inventory(inventory, group, host_line):
    """Helper function to add a host to a group in the inventory dictionary."""
    if group not in inventory:
        inventory[group] = []
    # Avoid adding duplicate entries to the same group
    if host_line not in inventory[group]:
        inventory[group].append(host_line)

def generate_inventory_file(instance_map, inventory_file="inventory.ini"):
    """
    Generates an Ansible-compatible inventory.ini file from the instance map.

    Args:
        instance_map (dict): A dictionary mapping instance names to IP addresses.
        inventory_file (str): The name of the inventory file to create.
    """
    print(f"\n--- Generating Ansible inventory file to {inventory_file} ---")
    
    inventory = {} # Structure: { 'group_name': ['host1 ansible_host=ip', 'host2...'] }

    # Iterate through the map of instances and IPs provided by Terraform
    for name, ip in instance_map.items():
        if not ip:
            continue
        
        hostname = name.replace('_', '-')
        host_line = f"{hostname} ansible_host={ip}"

        # Assign instances to logical groups based on their names
        if name.startswith('storage_node'):
            add_to_inventory(inventory, 'storage_nodes', host_line)
        elif name.startswith('file_receiver'):
            add_to_inventory(inventory, 'file_receivers', host_line)
        elif name == 'file_distributor':
            add_to_inventory(inventory, 'file_distributors', host_line)
        elif name == 'file_downloader':
            add_to_inventory(inventory, 'file_downloaders', host_line)
        elif name == 'kafka':
            add_to_inventory(inventory, 'kafka', host_line)
            #add_to_inventory(inventory, 'kafka_cluster', host_line) # Also part of a larger cluster
        elif name == 'zookeeper':
            add_to_inventory(inventory, 'zookeeper', host_line)
            #add_to_inventory(inventory, 'kafka_cluster', host_line) # Also part of a larger cluster
        elif name == 'postgres':
            add_to_inventory(inventory, 'postgres', host_line)
        elif name == 'frontend':
            add_to_inventory(inventory, 'frontend', host_line)
        elif name == 'load_balancer':
            add_to_inventory(inventory, 'load_balancer', host_line)
        elif name == 'test':
             add_to_inventory(inventory, 'test', host_line)
        else:
             add_to_inventory(inventory, 'ungrouped', host_line)

    # Write the generated inventory structure to the output file
    try:
        with open(inventory_file, "w", encoding='utf-8') as f:
            f.write(f"# This file was automatically generated by {os.path.basename(__file__)}\n")
            f.write("# Ansible inventory file.\n\n")

            for group, hosts in sorted(inventory.items()):
                f.write(f"[{group}]\n")
                for host in sorted(hosts):
                    f.write(f"{host}\n")
                f.write("\n")
        print(f"Ansible inventory file '{inventory_file}' created successfully.")
    except IOError as e:
        print(f"Error writing Ansible inventory file: {e}")


def run_terraform_and_generate_artifacts(terraform_dir=".", output_hosts_file="generated_hosts.txt", output_inventory_file="inventory.ini"):
    """
    Runs terraform apply, captures its output, and generates a custom hosts file
    and an Ansible inventory file.

    Args:
        terraform_dir (str): The directory where your Terraform configuration files are located.
        output_hosts_file (str): The name of the hosts-like text file to create.
        output_inventory_file (str): The name of the Ansible inventory file to create.
    """
    print(f"--- Running terraform apply in {terraform_dir} ---")
    try:
        # Run 'terraform apply'
        apply_command = ["terraform", "apply", "-auto-approve"]
        apply_process = subprocess.run(
            apply_command,
            cwd=terraform_dir,
            capture_output=True,
            text=True,
            check=True,
            encoding='utf-8'
        )
        print("Terraform apply output:")
        print(apply_process.stdout)
        if apply_process.stderr:
            print("Terraform apply errors (if any):")
            print(apply_process.stderr)

    except subprocess.CalledProcessError as e:
        print(f"Error running terraform apply: {e}")
        print(f"STDOUT: {e.stdout}")
        print(f"STDERR: {e.stderr}")
        return
    except FileNotFoundError:
        print("Error: 'terraform' command not found. Please ensure Terraform is installed and in your PATH.")
        return

    print("\n--- Fetching Terraform output in JSON format ---")
    try:
        # Get Terraform outputs in JSON format
        output_command = ["terraform", "output", "-json"]
        output_process = subprocess.run(
            output_command,
            cwd=terraform_dir,
            capture_output=True,
            text=True,
            check=True,
            encoding='utf-8'
        )
        terraform_outputs = json.loads(output_process.stdout)
        print("Terraform JSON output fetched successfully.")

    except subprocess.CalledProcessError as e:
        print(f"Error fetching terraform output: {e}")
        print(f"STDOUT: {e.stdout}")
        print(f"STDERR: {e.stderr}")
        return
    except json.JSONDecodeError:
        print("Error: Could not decode Terraform output as JSON. Is there any output?")
        print(f"Raw output: {output_process.stdout}")
        return
    except FileNotFoundError:
        print("Error: 'terraform' command not found. Please ensure Terraform is installed and in your PATH.")
        return

    hosts_entries = {}
    print("\n--- Parsing Terraform outputs for hosts file entries ---")

    # The new output is a single map called 'instance_floating_ips'
    instance_ips_output = terraform_outputs.get("instance_floating_ips")

    if instance_ips_output and 'value' in instance_ips_output and isinstance(instance_ips_output['value'], dict):
        # The 'value' field contains a dictionary of {"instance_name": "ip_address"}
        instance_ips_map = instance_ips_output['value']
        
        for name, ip in instance_ips_map.items():
            if not ip:
                print(f"Warning: IP address for '{name}' is empty. Skipping.")
                continue

            hostname = name.replace('_', '-')
            hosts_entries[ip] = hostname
            print(f"Found entry: {ip} -> {hostname}")

        # Now that we have the map, generate the inventory file
        generate_inventory_file(instance_ips_map, output_inventory_file)
            
    else:
        print("Error: Could not find the expected 'instance_floating_ips' map in the Terraform output.")
        print("Please ensure your Terraform configuration has an output block named 'instance_floating_ips'.")
        return

    print(f"\n--- Writing hosts-like file to {output_hosts_file} ---")
    try:
        with open(output_hosts_file, "w", encoding='utf-8') as f:
            f.write(f"# This file was automatically generated by {os.path.basename(__file__)}\n")
            f.write("# It contains host entries from the Terraform 'instance_floating_ips' output.\n\n")
            for ip, host in hosts_entries.items():
                f.write(f"{ip}\t{host}\n")
        print(f"Hosts-like file '{output_hosts_file}' created successfully.")
    except IOError as e:
        print(f"Error writing hosts-like file: {e}")

if __name__ == "__main__":
    run_terraform_and_generate_artifacts()
